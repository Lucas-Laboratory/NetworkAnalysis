{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import funcs\n",
    "import hubs\n",
    "import clusters as clust\n",
    "import cluster_graphs_figure as cgf\n",
    "import figures as f\n",
    "\n",
    "paper_folder = 'du_Plessis_et_al_2022/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import data:\n",
    "#### The functions here require access to a set of raw data.\n",
    "#### This can be loaded using 'funcs.load_data'.\n",
    "#### The format for 'data' object is a pandas DataFrame, with rows labelled as 'Region', and Columns use MultiIndex with 2 levels: 'group', and animal name (any string)\n",
    "#### Results of this are used to create most figures, and are already stored in threshold_results_dict.dat file in the paper folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With access to the data file, load it here:\n",
    "# data = funcs.load_data()\n",
    "# groups = data.columns.get_level_values('group').unique()\n",
    "\n",
    "# Or just set up group names:\n",
    "groups = ['naive_male', 'naive_female', 'trained_male', 'trained_female']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.linspace(0.005, 0.05, 10)\n",
    "threshold_type = 'p'\n",
    "method = 'pearson'\n",
    "\n",
    "thresholds_results_dict = {}\n",
    "thresholds = np.linspace(0.005, 0.05, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This initial analysis takes ~5 minutes to compute, and\n",
    "# requires access to the original data.\n",
    "# Alternatively can load from dat files in cell below\n",
    "\n",
    "for threshold in thresholds:\n",
    "    adj_mat_dict = funcs.get_adj_mat_dict_for_groups(data, groups,\n",
    "                                                threshold_type=threshold_type,\n",
    "                                                threshold=threshold,\n",
    "                                                method=method)\n",
    "    cluster_ids_dict = clust.get_cluster_ids_for_groups(data, groups,\n",
    "                                                threshold_type=threshold_type,\n",
    "                                                threshold=threshold,\n",
    "                                                method=method)\n",
    "    gr_dict = {}\n",
    "    hub_dict = {}\n",
    "    for group in groups:\n",
    "        gr_dict[group] = cgf.create_graph(adj_mat_dict[group])\n",
    "        hub_dict[group] = hubs.centrality_measures_with_hub_regions(data, \n",
    "                                    group=group,\n",
    "                                    threshold_type=threshold_type,\n",
    "                                    threshold=threshold,\n",
    "                                    method=method)\n",
    "    thresholds_results_dict[threshold] = (adj_mat_dict, cluster_ids_dict, hub_dict, gr_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('thresholds_results_dict.dat', 'wb') as f:\n",
    "    pickle.dump(thresholds_results_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hubs_all_thresholds = {}\n",
    "for group in groups:\n",
    "    hub_dict_list = []\n",
    "    for threshold in thresholds_results_dict.keys():\n",
    "        hub_dict_list.append(thresholds_results_dict[threshold][2][group])\n",
    "    hubs_all_thresholds[group] = hubs.hub_counts_for_multiple_trials(hub_dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hubs_all_thresholds.dat', 'wb') as f:\n",
    "    pickle.dump(hubs_all_thresholds, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The next 4 cells create and save lists of metrics for random networks for multiple thresholds, one cell per group\n",
    "#### These take some time to compute, and are already stored in .dat files in the repository if they are needed quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filename = 'metrics_naive_male_list.dat'\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"***********   \" + str(i) + \"     ***************\")\n",
    "    print(\"***********   \" + str(i) + \"     ***************\")\n",
    "    metrics_naive_male_list = funcs.calc_metrics_for_multiple_thresholds_with_randomizations(\n",
    "        data=data,\n",
    "        group='naive_male',\n",
    "        threshold_type='p',\n",
    "        thresholds=thresholds, #[0.025,0.05],\n",
    "        num_rands=100,\n",
    "        alpha=1.0\n",
    "    )\n",
    "\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, 'rb') as f:\n",
    "            metrics_list_prev = pickle.load(f)\n",
    "            metrics_naive_male_list.extend(metrics_list_prev)\n",
    "\n",
    "\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(metrics_naive_male_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'metrics_naive_female_list.dat'\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"***********   \" + str(i) + \"     ***************\")\n",
    "    print(\"***********   \" + str(i) + \"     ***************\")\n",
    "    metrics_naive_female_list = funcs.calc_metrics_for_multiple_thresholds_with_randomizations(\n",
    "        data=data,\n",
    "        group='naive_female',\n",
    "        threshold_type='p',\n",
    "        thresholds=thresholds, #[0.025,0.05],\n",
    "        num_rands=100,\n",
    "        alpha=1.0\n",
    "    )\n",
    "\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, 'rb') as f:\n",
    "            metrics_list_prev = pickle.load(f)\n",
    "            metrics_naive_female_list.extend(metrics_list_prev)\n",
    "\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(metrics_naive_female_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'metrics_trained_male_list.dat'\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"***********   \" + str(i) + \"     ***************\")\n",
    "    print(\"***********   \" + str(i) + \"     ***************\")\n",
    "    metrics_trained_male_list = funcs.calc_metrics_for_multiple_thresholds_with_randomizations(\n",
    "        data=data,\n",
    "        group='trained_male',\n",
    "        threshold_type='p',\n",
    "        thresholds=thresholds, #[0.025,0.05],\n",
    "        num_rands=100,\n",
    "        alpha=1.0\n",
    "    )\n",
    "\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, 'rb') as f:\n",
    "            metrics_list_prev = pickle.load(f)\n",
    "            metrics_trained_male_list.extend(metrics_list_prev)\n",
    "\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(metrics_trained_male_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'metrics_trained_female_list.dat'\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"***********   \" + str(i) + \"     ***************\")\n",
    "    print(\"***********   \" + str(i) + \"     ***************\")\n",
    "    metrics_trained_female_list = funcs.calc_metrics_for_multiple_thresholds_with_randomizations(\n",
    "        data=data,\n",
    "        group='trained_female',\n",
    "        threshold_type='p',\n",
    "        thresholds=thresholds, #[0.025,0.05],\n",
    "        num_rands=100,\n",
    "        alpha=1.0\n",
    "    )\n",
    "\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, 'rb') as f:\n",
    "            metrics_list_prev = pickle.load(f)\n",
    "            metrics_trained_female_list.extend(metrics_list_prev)\n",
    "\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(metrics_trained_female_list, f)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c5c34eb633c7dfe0a8267d20d2c67492b0a8fc69e9ddb3ba7193eac253eb6524"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
